\documentclass[11pt]{article}
\usepackage{a4, fullpage}
\usepackage{bibtopic}
\usepackage[small,compact]{titlesec}
\usepackage{float}
\usepackage{amssymb,amsmath}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\restylefloat{table}
%\usepackage{parskip}
%\usepackage{setspace}



\setlength{\parskip}{0.3cm}
\setlength{\parindent}{0cm}
\setlength{\textheight}{10.7in} %used to be 10
\setlength{\textwidth}{6.5in}
\setlength{\parskip}{2pt}
\addtolength{\oddsidemargin}{-.3in}
\addtolength{\evensidemargin}{-.3in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{.6in}



\begin{document}


\title{Assignment 3 \\ Group 30  }

\author{John Walker \and Adam Fiksen \and Giovanni Charles }

\date{\today}         % inserts today's date

\maketitle           % generates the title from the data above


\section{Results}
% Confuction matrices (for both types of networks)
% Average classification rate and recall, precision and F1 measures per class (part VIII).
\section{Fold Perfomance}
%Figure of the average performance per fold for both types of networks (part IX)
\section{Implementation Details}
% Brief summary of implementation details (e.g., (e.g., how you performed cross-validation,
% how you classified each example based on %the 6 outputs, 
%anything that you think it is important in your system implementation);
\section{Questions}
%1. Discuss how you obtained the optimal topology and optimal values of network parameters. Describe the performance measure you %used (and explain why you preferred it over other measures) and the different topologies / parameters you experimented with.
%2. Explain what strategy you employed to ensure good generalisation ability of the networks and overcome the problem of %overfitting.
%3. In Part VIII you used the optimal parameters that you found in part VI to train your networks. However, there is a problem with this approach, the data you used for validation at some point will be used for testing in cross-validation. Can you explain why this a problem? Ideally how should you optimise the parameters in cross-validation?
%4. Is there any difference in the classification performance of the two different classification approaches. Discuss the advantages / disadvantages of using 6 single-outut NNs vs. 1 six-output NNs.

\subsection{Discuss how you obtained the optimal topology and optimal values of network parameters. Describe the performance measure you used (and explain why you preferred it over other measures) and the different topologies / parameters you experimented with}

\subsection{Explain what strategy you employed to ensure good generalisation ability of the networks and overcome the problem of overfitting}

\subsection{In Part VIII you used the optimal parameters that you found in part VI to train your networks. However, there is a problem with this approach, the data you used for validation at some point will be used for testing in cross-validation. Can you explain why this a problem? Ideally how should you optimise the parameters in cross-validation?}

We were given a number of examples and targets we then divided these into  2/3 training and 1/3 validation data. The validation data then influences the neural network which is produced. Essentially you are training the neural network to perform well for the validation data and you hope that the validation data is large and representitive enough so that the neural network you produce generalises well and can classify unseen examples. When you come to perform cross validation you then use a portion of the data as testing data and the rest as training/validation data. This means that eventually you will be testing a section of data which was the network was geared for this will produce a very low error and thus will skew the average error rate affecting your cross validation result. To combat this the parameters (data) given to cross validation should be rearranged into a random order this will reduce the effect of any 'seen' data and any effects will be evenly spread and the average will not be skewed, althought it could be raised very slightly.

\subsection{Is there any difference in the classification performance of the two different classification approaches. Discuss the advantages / disadvantages of using 6 single-outut NNs vs. 1 six-output NNs}



\section{Code Flow Chart}

\end{document}
